---
title: "Image Dataset Generation (Artifeye)"
excerpt: "Creating a labelled dataset from raw low-resolution, low-contrast microscopic images. Used OpenCV, Tensorflow, AWS."
collection: portfolio
---

While I was at [Artifeye](https://www.artifeye.com/), I worked on an image segmentation problem. In the textile industry, contents of threads are analyzed by cutting a cross-section of the thread counting the individual fibers. There are two problems with this approach. First problem is that the result is an approximation since the content of the thread is calculated by multiplying the *average fiber area* by the number of fibers. Second problem is that the fibers are not always easy to distinguish and a trained analyst needs to spend a lot of time counting these fibers.

## Introduction

The project I worked on aimed to automate this process. The cross-section image would be fed to the algorithm by the operator and the algoritm would output the contents of the fiber. An example thread cross-section can be seen below. Each whiteish blob is an individual fiber. Our task is to segment these individual fibers and find area & type of each fiber. This task was not easy because the images are usually low contrast, blobs are adjacent to each other and different types of fibers look alike in the photos.

<br/><img src='/images/portfolio/kesit-sample.BMP'>

## Issues with the Task

The data was raw, meaning that there were no labels associated with the data. We had to generate our own labels if we wanted to train machine learning models.

Another issue was that we didn't have much data on the real task we wanted to solve: finding percentages of each fiber type when the thread has a mixture of different fibers. We only had (unlabelled) data of the pure threads where there was only one type of fiber.

## Segmentation

First problem to solve was the segmentation of fibers. Then we could go on to classification.

### Pure OpenCV

My collegues had made some progress before I started working at Artifeye. They had used series of OpenCV transformations with `cvtColor`, `adaptiveThreshold`, `medianBlur`, `erode`, `dilate`. They had been somewhat succesful at detecting the fibers:

<br/><img src='/images/portfolio/fiber-detection-with-cv.png'>

Attempts to train a CNN model and classify the fibers were not very succesful.

### Multi-tolerance Region Growing

I did some research on low contrast image segmentation and one paper named ["Detection and Classification of Mammographic Calcifications"](https://www.worldscientific.com/doi/abs/10.1142/S0218001493000686) drew my attention. I wrote a module in Python to apply the Multi-tolerance Region Growing (MTRG) to our data.

I also did some modifications to the algorithm so that it would work on our data. Our data had non-uniform shade. This meant that I had to change the seed pixel selection algorithm to make a grid search instead of looking at all of the image at once.

Below you can see a sample from the results of the first MTRG experiment I did. It is composed of three images. To the left there is the original image, middle is the regions detected with MTRG, to the right you can see the filtered regions after the regions which are too big and too small are removed.

<br/><img src='/images/portfolio/mtrg-sample.png'>

Below, you can see regions found with MTRG for different types of fibers:

<br/><img src='/images/portfolio/mtrg-sample-2.png'>

We also attempted to classify the fibers found with MTRG but the classification was not successful. Labels we generated were rather useful in the next step of the segmentation task.

### CE-Net & Watersheding

In the next stage, I created a dataset with the labels generated with MTRG segmentation. Labels of the MTRG segmentation were imperfect. Therefore I converted our labels to the format accepted by [VIA](https://www.robots.ox.ac.uk/~vgg/software/via/via.html) and uploaded our images and labels there. Then we handpicked the good and bad labels, replacing the bad labels with hand-drawn contours. Following is a sample from the end result dataset. You can see that some contours are generated by MTRG since they are more detailed while others simply have a hand-drawn ellipse.

<br/><img src='/images/portfolio/dataset-sample.png'>

We trained a [CE-Net model](https://arxiv.org/abs/1903.02740) with this dataset. The model was successful at generating a binary mask segmenting the background from the fibers. I then used watersheding to find individual fibers:

<br/><img src='/images/portfolio/ce-net-output.PNG'>

Combination of a CE-Net model trained with the labels from MTRG and the watersheding model proved to be succesful at segmenting fibers in the images. We were able to use this method to create bigger datasets for training better models and achieve our main goal of classifying these fibers.

## Classification

We tried many methods for classifying the fibers in the images:
- Extracting images of the individual fibers we found and training a classifier
- Finding the center of a fiber and calculating the distance of the contour boundaries to the center, generating a series data. Then extracting features from the series data and training a classifier
- Training deep learning models such as Mask-RCNN and CE-Net using the datasets we generated with CE-Net & Watersheding.

## Conclusion

We were able to create a good segmentation pipeline but couldn't match this success when classifying the fibers. The project was a great experience for me where I:
- Worked with unlabelled image data
- Used AWS tools such as EC2 and S3
- Experimented with different image processing methods and deep learning algorithms.